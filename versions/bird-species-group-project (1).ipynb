{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bird Species Classifier for AML project using TensorFlow\n## University of Vienna, SS 2022\n---\n### Goal: An image recognition model\n#### Open Questions:\n* Which methods to use? \n* Which model to train?\n* What is the class_dict.csv for?\n* Do we need both valid set and test set?","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:35:47.603306Z","iopub.execute_input":"2022-05-27T16:35:47.603691Z","iopub.status.idle":"2022-05-27T16:35:47.607886Z","shell.execute_reply.started":"2022-05-27T16:35:47.603659Z","shell.execute_reply":"2022-05-27T16:35:47.607014Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport keras_preprocessing #?\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import layers,mixed_precision\n\n# Model Selection\nfrom sklearn.metrics import confusion_matrix, classification_report\n# To search directories\nimport os\nimport glob\n# To visualize data\nimport PIL # for image files\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#sns.set_style('darkgrid')","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.250060Z","iopub.execute_input":"2022-05-29T11:25:06.250517Z","iopub.status.idle":"2022-05-29T11:25:06.256603Z","shell.execute_reply.started":"2022-05-29T11:25:06.250485Z","shell.execute_reply":"2022-05-29T11:25:06.255723Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"# 1. Examine and understand data\n## CSV data\nThe ``birds.csv`` contains information of the dataset. Let's look into the structure of the data.","metadata":{}},{"cell_type":"code","source":"# Create a dataframe from the csv\nbirds_df = pd.read_csv(\"../input/100-bird-species/birds.csv\")\n# clean column names\nbirds_df.columns = [col.replace(' ', '_').lower() for col in birds_df.columns]\nbirds_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.330825Z","iopub.execute_input":"2022-05-29T11:25:06.331867Z","iopub.status.idle":"2022-05-29T11:25:06.431652Z","shell.execute_reply.started":"2022-05-29T11:25:06.331828Z","shell.execute_reply":"2022-05-29T11:25:06.430579Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"birds_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.433563Z","iopub.execute_input":"2022-05-29T11:25:06.433982Z","iopub.status.idle":"2022-05-29T11:25:06.467939Z","shell.execute_reply.started":"2022-05-29T11:25:06.433942Z","shell.execute_reply":"2022-05-29T11:25:06.466974Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"birds_df.value_counts(\"data_set\").head()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.539772Z","iopub.execute_input":"2022-05-29T11:25:06.540264Z","iopub.status.idle":"2022-05-29T11:25:06.553997Z","shell.execute_reply.started":"2022-05-29T11:25:06.540204Z","shell.execute_reply":"2022-05-29T11:25:06.553257Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# Frequency of bird species in the whole dataset\nprint(\"|species | f|\")\nbirds_df.value_counts(\"class_index\")","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.624394Z","iopub.execute_input":"2022-05-29T11:25:06.625417Z","iopub.status.idle":"2022-05-29T11:25:06.637681Z","shell.execute_reply.started":"2022-05-29T11:25:06.625367Z","shell.execute_reply":"2022-05-29T11:25:06.636744Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# Look at csv entries for one single bird\n\n#mask = birds_df['labels'].str.contains(\"ABBOTTS BABBLER\") # Search for text fragment\n#mask = birds_df.query('labels == \"ABBOTTS BABBLER\"') # query for name (case sensitive!)\nmask = birds_df.loc[birds_df['class_index'] == 0]\nprint(mask.value_counts(\"data_set\"))\nmask","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.733907Z","iopub.execute_input":"2022-05-29T11:25:06.734688Z","iopub.status.idle":"2022-05-29T11:25:06.754698Z","shell.execute_reply.started":"2022-05-29T11:25:06.734637Z","shell.execute_reply":"2022-05-29T11:25:06.753733Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"### Image data","metadata":{}},{"cell_type":"code","source":"# File directories\nroot_dir = \"../input/100-bird-species\"\ntrain_dir = \"../input/100-bird-species/train\"\nvalid_dir = \"../input/100-bird-species/valid\"\ntest_dir = \"../input/100-bird-species/test\"\npretest_dir = \"../input/100-bird-species/images to test\"\ndirs = [pretest_dir, train_dir, valid_dir, test_dir]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.826022Z","iopub.execute_input":"2022-05-29T11:25:06.826489Z","iopub.status.idle":"2022-05-29T11:25:06.832337Z","shell.execute_reply.started":"2022-05-29T11:25:06.826454Z","shell.execute_reply":"2022-05-29T11:25:06.831162Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"### Plot random birds","metadata":{}},{"cell_type":"code","source":"def plot_random_bird(dirname):\n    import random\n    \"\"\"\n    takes the directory as input and prints 5 random images from the randomly choosen class.\n    \"\"\"\n    target_class = random.choice(os.listdir(dirname))\n    target_folder = os.path.join(dirname,target_class)\n    random_image = random.sample(os.listdir(target_folder),5)\n \n    plt.figure(figsize=(16,5))\n    for i in range(5):\n        \n        plt.subplot(1,5,i+1)\n        img = tf.io.read_file(os.path.join(target_folder,random_image[i]))\n        img = tf.io.decode_image(img)\n        plt.imshow(img)\n        plt.title(f'{target_class}\\n{img.shape}')\n        plt.axis(False)\n        \nplot_random_bird(valid_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:06.964028Z","iopub.execute_input":"2022-05-29T11:25:06.965132Z","iopub.status.idle":"2022-05-29T11:25:07.404815Z","shell.execute_reply.started":"2022-05-29T11:25:06.965079Z","shell.execute_reply":"2022-05-29T11:25:07.404094Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"def showFirstBird(bird_name=\"MALLARD DUCK\"):\n    \"\"\"\n    Print out file paths of images in the valid_dir and show the first image of a given species.\n    \"\"\"\n    import glob\n    img_files = []\n    for img in glob.glob(os.path.join(valid_dir, bird_name)+\"/*\"):\n        img_files.append(img)\n        \n    for i in img_files:\n        print(i) # Print file path\n        ifile = tf.io.read_file(i) # Reads the contents of file\n        img_dec = tf.io.decode_image(ifile) # Decodes an image file\n        print(\"File shape: \", img_dec.shape, \"\\n\")\n        \n    img = PIL.Image.open(str(img_files[0]))\n    return img\n    \nshowFirstBird()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:07.406326Z","iopub.execute_input":"2022-05-29T11:25:07.406755Z","iopub.status.idle":"2022-05-29T11:25:07.452555Z","shell.execute_reply.started":"2022-05-29T11:25:07.406724Z","shell.execute_reply":"2022-05-29T11:25:07.451670Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data for model","metadata":{}},{"cell_type":"markdown","source":"### Generate tf.data.Dataset objects from image files in directories","metadata":{}},{"cell_type":"code","source":"\"\"\"\nGPUs and TPUs can radically reduce the time required to execute a single training step. \nAchieving peak performance requires an efficient input pipeline that delivers data for \nthe next step before the current step has finished. The tf.data API helps to build flexible \nand efficient input pipelines.\n~ https://www.tensorflow.org/guide/data_performance\n\"\"\"\nIMAGE_SIZE=(224,224) # constant value\n\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=train_dir,\n    labels='inferred',\n    label_mode='categorical',\n    batch_size=32, # default\n    image_size=IMAGE_SIZE,\n    shuffle=True   # default\n)\nclass_names = train_data.class_names\nnum_classes = len(class_names)\n\nval_data = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=valid_dir,\n    labels='inferred',\n    label_mode='categorical',\n    batch_size=32, # default\n    image_size=IMAGE_SIZE,\n    shuffle=True   # default\n)\n\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=test_dir,\n    labels='inferred',\n    label_mode='categorical',\n    batch_size=32, # default\n    image_size=IMAGE_SIZE,\n    shuffle=False\n)\n#---------------------------------------------------------------#\n\"\"\"\nThe tf.data API provides the tf.data.Dataset.prefetch transformation. It can be used \nto decouple the time when data is produced from the time when data is consumed. In particular, \nthe transformation uses a background thread and an internal buffer to prefetch elements from \nthe input dataset ahead of the time they are requested. The number of elements to prefetch \nshould be equal to (or possibly greater than) the number of batches consumed by a single training step. \nYou could either manually tune this value, or set it to tf.data.AUTOTUNE, which will prompt the \ntf.data runtime to tune the value dynamically at runtime.\n~ https://www.tensorflow.org/guide/data_performance\n\"\"\"\n\n# Output the number of classes found in the directory \ntrain_data_pf = train_data.prefetch(buffer_size = tf.data.AUTOTUNE)\nval_data_pf = val_data.prefetch(buffer_size = tf.data.AUTOTUNE)\ntest_data_pf = test_data.prefetch(buffer_size = tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:07.453689Z","iopub.execute_input":"2022-05-29T11:25:07.454014Z","iopub.status.idle":"2022-05-29T11:25:12.307910Z","shell.execute_reply.started":"2022-05-29T11:25:07.453985Z","shell.execute_reply":"2022-05-29T11:25:12.306976Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:12.311734Z","iopub.execute_input":"2022-05-29T11:25:12.312047Z","iopub.status.idle":"2022-05-29T11:25:12.319080Z","shell.execute_reply.started":"2022-05-29T11:25:12.312018Z","shell.execute_reply":"2022-05-29T11:25:12.318147Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"# The Model \n## Model architecture\nSource: http://bit.ly/2lXXdw5","metadata":{}},{"cell_type":"markdown","source":"### Questions:\n- What is ``tf.keras.layers.Conv2D`` ?\n- What is ``tf.keras.layers.MaxPooling2D`` ?\n- What is ``tf.keras.layers.Flatten`` ?\n- What is ``tf.keras.layers.Dropout`` ?\n- What is ``tf.keras.layers.Dense`` ?\n- What is ```` ?\n\n- ...","metadata":{}},{"cell_type":"code","source":"INPUT_SHAPE=(224,224,3) # constant value\n\n# Defining the architecture of the CNN (Convolutional Neural Network)\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=INPUT_SHAPE),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # The second convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    # The third convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    # The fourth convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    # Flatten the results to feed into a DNN (Dense Neural Network)\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(3, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:12.320589Z","iopub.execute_input":"2022-05-29T11:25:12.321124Z","iopub.status.idle":"2022-05-29T11:25:12.531161Z","shell.execute_reply.started":"2022-05-29T11:25:12.321090Z","shell.execute_reply":"2022-05-29T11:25:12.530244Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:12.534127Z","iopub.execute_input":"2022-05-29T11:25:12.534896Z","iopub.status.idle":"2022-05-29T11:25:12.539977Z","shell.execute_reply.started":"2022-05-29T11:25:12.534862Z","shell.execute_reply":"2022-05-29T11:25:12.539357Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"## Compile and train model ","metadata":{}},{"cell_type":"markdown","source":"### Links:\n- TF model.fit() -> https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n- ...","metadata":{}},{"cell_type":"code","source":"model.summary()\n\nmodel.compile(\n    loss='categorical_crossentropy', \n    optimizer='rmsprop', \n    metrics=['accuracy']\n)\n\nhistory = model.fit( ,\n    train_data, \n    epochs=25, \n    steps_per_epoch=20, \n    validation_data=valid_data, \n    validation_steps=3,\n    verbose=1, \n)\n\nmodel.save(\"rps.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:12.540983Z","iopub.execute_input":"2022-05-29T11:25:12.541717Z","iopub.status.idle":"2022-05-29T11:25:12.552124Z","shell.execute_reply.started":"2022-05-29T11:25:12.541661Z","shell.execute_reply":"2022-05-29T11:25:12.550998Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"# Results\n## Visualize Training","metadata":{}},{"cell_type":"code","source":"#import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:25:12.553640Z","iopub.status.idle":"2022-05-29T11:25:12.554476Z","shell.execute_reply.started":"2022-05-29T11:25:12.554179Z","shell.execute_reply":"2022-05-29T11:25:12.554208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# README\nafter the first meeting\n\n### Aufteilung\n- keras tensorflow - Clemens\n- pytorch - Jakob\n- PCA + preprocessing - Lena \n\n\n### Methoden \n- pca?\n- image segementation\n- Wie laden wir die Bilder von der CSV ins Notebook?\n- Wieviele Datenreihen brauchen wir? \ndata set\n| train    58388 | test      2000 | valid     2000 |\n","metadata":{}},{"cell_type":"markdown","source":"# Links\n## Good Notebook for reference\n### https://www.kaggle.com/code/ashwinshetgaonkar/bird-classifier-tensorflow-beginner\n\n## Learn TensorFlow in this notebook\n### http://bit.ly/2lXXdw5","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}